defaults:
  - training_hyperparams: cityscapes_stdc_train_params
  - dataset_params: cityscapes_dataset_params

arch_params:
  num_classes: 19
  use_aux_heads: True
  sync_bn: True
  external_checkpoint_path: "/home/shay.aharon/stdc_backbones/stdc1_imagenet_pretrained.pth"
  load_backbone: True
  load_weights_only: True
  strict_load: no_key_matching

dataset_params:
  _convert_: all
  batch_size: 8
  val_batch_size: 8
  color_jitter: 0.5
  random_scales:
  - 0.125
  - 1.5
  crop_size:
    - 1024
    - 512
  eval_scale: 0.5
  image_mask_transforms_aug:
    _target_: torchvision.transforms.Compose
    transforms:
      - _target_: super_gradients.training.utils.segmentation_utils.ColorJitterSeg
        brightness: ${dataset_params.color_jitter}
        contrast: ${dataset_params.color_jitter}
        saturation: ${dataset_params.color_jitter}

      - _target_: super_gradients.training.utils.segmentation_utils.RandomFlip

      - _target_: super_gradients.training.utils.segmentation_utils.RandomRescale
        scales: ${dataset_params.random_scales}

      - _target_: super_gradients.training.utils.segmentation_utils.PadShortToCropSize
        crop_size: ${dataset_params.crop_size}
        fill_mask: 19

      - _target_: super_gradients.training.utils.segmentation_utils.CropImageAndMask
        crop_size: ${dataset_params.crop_size}
        mode: random

  image_mask_transforms:
    _target_: torchvision.transforms.Compose
    transforms:
      - _target_: super_gradients.training.utils.segmentation_utils.Rescale
        scale_factor: 0.5

dataset_interface:
  _target_: super_gradients.training.datasets.dataset_interfaces.dataset_interface.CityscapesDatasetInterface
  dataset_params: ${dataset_params}

data_loader_num_workers: 10

model_checkpoints_location: local
load_checkpoint: False
load_backbone: True
external_checkpoint_path:

architecture: stdc1_seg
experiment_name: ${architecture}50_cityscapes

sg_model:
  _target_: super_gradients.SgModel
  experiment_name: ${experiment_name}



