{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Imports:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import super_gradients\n",
    "from super_gradients.training import SgModel, MultiGPUMode\n",
    "from super_gradients.training.datasets.dataset_interfaces.dataset_interface import \\\n",
    "    PascalVOCUnifiedDetectionDataSetInterface\n",
    "from super_gradients.training.models.detection_models.yolov5 import YoloV5PostPredictionCallback\n",
    "from super_gradients.training.utils.detection_utils import base_detection_collate_fn\n",
    "from super_gradients.training.metrics import DetectionMetrics\n",
    "from super_gradients.training.utils.detection_utils import Anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "super_gradients.init_trainer()\n",
    "\n",
    "distributed = super_gradients.is_distributed()\n",
    "\n",
    "# DEFINE DATASET PARAMS FOR PASCAL VOC\n",
    "dataset_params = {\"batch_size\": 48,\n",
    "                  \"val_batch_size\": 48,\n",
    "                  \"train_image_size\": 512,\n",
    "                  \"val_image_size\": 512,\n",
    "                  \"val_collate_fn\": base_detection_collate_fn,\n",
    "                  \"train_collate_fn\": base_detection_collate_fn,\n",
    "                  \"train_sample_loading_method\": \"mosaic\",\n",
    "                  \"val_sample_loading_method\": \"default\",\n",
    "                  \"dataset_hyper_param\": {\n",
    "                      \"hsv_h\": 0.0138,  # IMAGE HSV-Hue AUGMENTATION (fraction)\n",
    "                      \"hsv_s\": 0.664,  # IMAGE HSV-Saturation AUGMENTATION (fraction)\n",
    "                      \"hsv_v\": 0.464,  # IMAGE HSV-Value AUGMENTATION (fraction)\n",
    "                      \"degrees\": 0.373,  # IMAGE ROTATION (+/- deg)\n",
    "                      \"translate\": 0.245,  # IMAGE TRANSLATION (+/- fraction)\n",
    "                      \"scale\": 0.898,  # IMAGE SCALE (+/- gain)\n",
    "                      \"shear\": 0.602,\n",
    "                      \"mixup\": 0.243  # MIXUP PROBABILITY\n",
    "                  },\n",
    "                  \"download\": True,\n",
    "                  \"data_root\": \"/home/shay.aharon/data/pascal_unified_coco_format\"\n",
    "                  }"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# INITIALIZE SG MODEL INSTANCE, AND A PASCAL VOC DATASET INTERFACE\n",
    "model = SgModel(\"yolov5m_pascal_finetune\", ckpt_root_dir=\"/home/shay.aharon/notebook_ckpts/\")\n",
    "dataset_interface = PascalVOCUnifiedDetectionDataSetInterface(dataset_params=dataset_params, cache_labels=True)\n",
    "\n",
    "# CONNECTING THE DATASET INTERFACE WILL SET SGMODEL'S CLASSES ATTRIBUTE ACCORDING TO PASCAL VOC\n",
    "model.connect_dataset_interface(dataset_interface, data_loader_num_workers=8)\n",
    "\n",
    "# THIS IS WHERE THE MAGIC HAPPENS- SINCE SGMODEL'S CLASSES ATTRIBUTE WAS SET TO BE DIFFERENT FROM COCO'S, AFTER\n",
    "# LOADING THE PRETRAINED YOLO_V5M, IT WILL CALL IT'S REPLACE_HEAD METHOD AND CHANGE IT'S DETECT LAYER ACCORDING\n",
    "# TO PASCAL VOC CLASSES\n",
    "model.build_model(\"yolo_v5m\", arch_params={\"pretrained_weights\": \"coco\"})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# WE NOW TUNE THE 3 NORMALIZERS ACCORDING TO THE NEW DATASET ATTRIBUTES,\n",
    "network = model.net\n",
    "network = network.module if hasattr(network, 'module') else network\n",
    "num_levels = network._head._modules_list[-1].detection_layers_num\n",
    "train_image_size = dataset_params[\"train_image_size\"]\n",
    "\n",
    "num_branches_norm = 3. / num_levels\n",
    "num_classes_norm = len(model.classes) / 80.\n",
    "image_size_norm = train_image_size / 640.\n",
    "\n",
    "# DEFINE TRAINING PARAMS. SEE DOCS FOR THE FULL LIST.\n",
    "training_params = {\"max_epochs\": 50,\n",
    "                   \"lr_mode\": \"cosine\",\n",
    "                   \"initial_lr\": 0.0032,\n",
    "                   \"cosine_final_lr_ratio\": 0.12,\n",
    "                   \"lr_warmup_epochs\": 2,\n",
    "                   \"warmup_bias_lr\": 0.05,  # LR TO START FROM DURING WARMUP (DROPS DOWN DURING WARMUP EPOCHS) FOR BIAS.\n",
    "                   \"loss\": \"yolo_v5_loss\",\n",
    "                   \"criterion_params\": {\"anchors\": Anchors(\n",
    "                       anchors_list=[[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119],\n",
    "                                     [116, 90, 156, 198, 373, 326]], strides=[8, 16, 32]),  # MODEL'S ANCHORS\n",
    "                       \"box_loss_gain\": 0.0296 * num_branches_norm,  # COEF FOR BOX LOSS COMPONENT, NORMALIZED\n",
    "                       \"cls_loss_gain\": 0.243 * num_classes_norm * num_branches_norm,  # COEF FOR CLASSIFICATION\n",
    "                                                                                       # LOSS COMPONENT, NORMALIZED\n",
    "                       \"cls_pos_weight\": 0.631,  # CLASSIFICATION BCE POSITIVE CLASS WEIGHT\n",
    "                       \"obj_loss_gain\": 0.301 * image_size_norm ** 2 * num_branches_norm,  # OBJECT BCE COEF, NORMALIZED\n",
    "                       \"obj_pos_weight\": 0.911,  # OBJECT BCE POSITIVE CLASS WEIGHT\n",
    "                       \"anchor_threshold\": 2.91  # RATIO DEFINING THE SIZE RANGE OF AN ANCHOR.\n",
    "                   },\n",
    "                   \"optimizer\": \"SGD\",\n",
    "                   \"warmup_momentum\": 0.5,\n",
    "                   \"optimizer_params\": {\"momentum\": 0.843,\n",
    "                                        \"weight_decay\": 0.00036,\n",
    "                                        \"nesterov\": True},\n",
    "                   \"ema\": True,\n",
    "                   \"train_metrics_list\": [],\n",
    "                   \"valid_metrics_list\": [DetectionMetrics(post_prediction_callback=YoloV5PostPredictionCallback(),\n",
    "                                                           num_cls=len(\n",
    "                                                               dataset_interface.classes))],\n",
    "                   \"loss_logging_items_names\": [\"GIoU\", \"obj\", \"cls\", \"Loss\"],\n",
    "                   \"metric_to_watch\": \"mAP@0.50:0.95\",\n",
    "                   \"greater_metric_to_watch_is_better\": True,\n",
    "                   \"warmup_mode\": \"yolov5_warmup\"}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# FINALLY, CALL TRAIN\n",
    "model.train(training_params=training_params)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}