<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>super_gradients.training.datasets package &mdash; SuperGradients 1.0 documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="super_gradients.training.datasets.classification_datasets package" href="super_gradients.training.datasets.classification_datasets.html" />
    <link rel="prev" title="super_gradients.training package" href="super_gradients.training.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> SuperGradients
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="intro.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="intro.html#installation">Installation</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="super_gradients.training.html">super_gradients.training package</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="super_gradients.training.html#subpackages">Subpackages</a><ul class="current">
<li class="toctree-l3 current"><a class="current reference internal" href="#">super_gradients.training.datasets package</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#subpackages">Subpackages</a></li>
<li class="toctree-l4"><a class="reference internal" href="#submodules">Submodules</a></li>
<li class="toctree-l4"><a class="reference internal" href="#module-super_gradients.training.datasets.all_datasets">super_gradients.training.datasets.all_datasets module</a></li>
<li class="toctree-l4"><a class="reference internal" href="#module-super_gradients.training.datasets.auto_augment">super_gradients.training.datasets.auto_augment module</a></li>
<li class="toctree-l4"><a class="reference internal" href="#module-super_gradients.training.datasets.data_augmentation">super_gradients.training.datasets.data_augmentation module</a></li>
<li class="toctree-l4"><a class="reference internal" href="#module-super_gradients.training.datasets.datasets_conf">super_gradients.training.datasets.datasets_conf module</a></li>
<li class="toctree-l4"><a class="reference internal" href="#module-super_gradients.training.datasets.datasets_utils">super_gradients.training.datasets.datasets_utils module</a></li>
<li class="toctree-l4"><a class="reference internal" href="#module-super_gradients.training.datasets.mixup">super_gradients.training.datasets.mixup module</a></li>
<li class="toctree-l4"><a class="reference internal" href="#module-super_gradients.training.datasets.sg_dataset">super_gradients.training.datasets.sg_dataset module</a></li>
<li class="toctree-l4"><a class="reference internal" href="#module-super_gradients.training.datasets">Module contents</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="super_gradients.training.exceptions.html">super_gradients.training.exceptions package</a></li>
<li class="toctree-l3"><a class="reference internal" href="super_gradients.training.legacy.html">super_gradients.training.legacy package</a></li>
<li class="toctree-l3"><a class="reference internal" href="super_gradients.training.losses.html">super_gradients.training.losses package</a></li>
<li class="toctree-l3"><a class="reference internal" href="super_gradients.training.metrics.html">super_gradients.training.metrics package</a></li>
<li class="toctree-l3"><a class="reference internal" href="super_gradients.training.models.html">super_gradients.training.models package</a></li>
<li class="toctree-l3"><a class="reference internal" href="super_gradients.training.sg_model.html">super_gradients.training.sg_model package</a></li>
<li class="toctree-l3"><a class="reference internal" href="super_gradients.training.utils.html">super_gradients.training.utils package</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="super_gradients.training.html#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="super_gradients.training.html#module-super_gradients.training.params">super_gradients.training.params module</a></li>
<li class="toctree-l2"><a class="reference internal" href="super_gradients.training.html#module-super_gradients.training.pretrained_models">super_gradients.training.pretrained_models module</a></li>
<li class="toctree-l2"><a class="reference internal" href="super_gradients.training.html#module-super_gradients.training">Module contents</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">SuperGradients</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="super_gradients.training.html">super_gradients.training package</a> &raquo;</li>
      <li>super_gradients.training.datasets package</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/super_gradients.training.datasets.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="super-gradients-training-datasets-package">
<h1>super_gradients.training.datasets package<a class="headerlink" href="#super-gradients-training-datasets-package" title="Permalink to this headline"></a></h1>
<section id="subpackages">
<h2>Subpackages<a class="headerlink" href="#subpackages" title="Permalink to this headline"></a></h2>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="super_gradients.training.datasets.classification_datasets.html">super_gradients.training.datasets.classification_datasets package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="super_gradients.training.datasets.classification_datasets.html#module-super_gradients.training.datasets.classification_datasets">Module contents</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="super_gradients.training.datasets.dataset_interfaces.html">super_gradients.training.datasets.dataset_interfaces package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="super_gradients.training.datasets.dataset_interfaces.html#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="super_gradients.training.datasets.dataset_interfaces.html#module-super_gradients.training.datasets.dataset_interfaces.dataset_interface">super_gradients.training.datasets.dataset_interfaces.dataset_interface module</a></li>
<li class="toctree-l2"><a class="reference internal" href="super_gradients.training.datasets.dataset_interfaces.html#module-super_gradients.training.datasets.dataset_interfaces">Module contents</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="super_gradients.training.datasets.detection_datasets.html">super_gradients.training.datasets.detection_datasets package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="super_gradients.training.datasets.detection_datasets.html#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="super_gradients.training.datasets.detection_datasets.html#module-super_gradients.training.datasets.detection_datasets.coco_detection">super_gradients.training.datasets.detection_datasets.coco_detection module</a></li>
<li class="toctree-l2"><a class="reference internal" href="super_gradients.training.datasets.detection_datasets.html#module-super_gradients.training.datasets.detection_datasets.detection_dataset">super_gradients.training.datasets.detection_datasets.detection_dataset module</a></li>
<li class="toctree-l2"><a class="reference internal" href="super_gradients.training.datasets.detection_datasets.html#module-super_gradients.training.datasets.detection_datasets.pascal_voc_detection">super_gradients.training.datasets.detection_datasets.pascal_voc_detection module</a></li>
<li class="toctree-l2"><a class="reference internal" href="super_gradients.training.datasets.detection_datasets.html#module-super_gradients.training.datasets.detection_datasets">Module contents</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="super_gradients.training.datasets.segmentation_datasets.html">super_gradients.training.datasets.segmentation_datasets package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="super_gradients.training.datasets.segmentation_datasets.html#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="super_gradients.training.datasets.segmentation_datasets.html#module-super_gradients.training.datasets.segmentation_datasets.cityscape_segmentation">super_gradients.training.datasets.segmentation_datasets.cityscape_segmentation module</a></li>
<li class="toctree-l2"><a class="reference internal" href="super_gradients.training.datasets.segmentation_datasets.html#module-super_gradients.training.datasets.segmentation_datasets.coco_segmentation">super_gradients.training.datasets.segmentation_datasets.coco_segmentation module</a></li>
<li class="toctree-l2"><a class="reference internal" href="super_gradients.training.datasets.segmentation_datasets.html#module-super_gradients.training.datasets.segmentation_datasets.pascal_aug_segmentation">super_gradients.training.datasets.segmentation_datasets.pascal_aug_segmentation module</a></li>
<li class="toctree-l2"><a class="reference internal" href="super_gradients.training.datasets.segmentation_datasets.html#module-super_gradients.training.datasets.segmentation_datasets.pascal_voc_segmentation">super_gradients.training.datasets.segmentation_datasets.pascal_voc_segmentation module</a></li>
<li class="toctree-l2"><a class="reference internal" href="super_gradients.training.datasets.segmentation_datasets.html#module-super_gradients.training.datasets.segmentation_datasets.segmentation_dataset">super_gradients.training.datasets.segmentation_datasets.segmentation_dataset module</a></li>
<li class="toctree-l2"><a class="reference internal" href="super_gradients.training.datasets.segmentation_datasets.html#module-super_gradients.training.datasets.segmentation_datasets">Module contents</a></li>
</ul>
</li>
</ul>
</div>
</section>
<section id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this headline"></a></h2>
</section>
<section id="module-super_gradients.training.datasets.all_datasets">
<span id="super-gradients-training-datasets-all-datasets-module"></span><h2>super_gradients.training.datasets.all_datasets module<a class="headerlink" href="#module-super_gradients.training.datasets.all_datasets" title="Permalink to this headline"></a></h2>
<dl class="py exception">
<dt class="sig sig-object py" id="super_gradients.training.datasets.all_datasets.DataSetDoesNotExistException">
<em class="property"><span class="pre">exception</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.datasets.all_datasets.</span></span><span class="sig-name descname"><span class="pre">DataSetDoesNotExistException</span></span><a class="reference internal" href="_modules/super_gradients/training/datasets/all_datasets.html#DataSetDoesNotExistException"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.datasets.all_datasets.DataSetDoesNotExistException" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Exception</span></code></p>
<p>The requested dataset does not exist, or is not implemented.</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.datasets.all_datasets.SgLibraryDatasets">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.datasets.all_datasets.</span></span><span class="sig-name descname"><span class="pre">SgLibraryDatasets</span></span><a class="reference internal" href="_modules/super_gradients/training/datasets/all_datasets.html#SgLibraryDatasets"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.datasets.all_datasets.SgLibraryDatasets" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Holds all of the different library dataset dictionaries, by DL Task mapping</p>
<blockquote>
<div><dl class="simple">
<dt>Attributes:</dt><dd><p>CLASSIFICATION          Dictionary of Classification Data sets
OBJECT_DETECTION        Dictionary of Object Detection Data sets
SEMANTIC_SEGMENTATION   Dictionary of Semantic Segmentation Data sets</p>
</dd>
</dl>
</div></blockquote>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.datasets.all_datasets.SgLibraryDatasets.CLASSIFICATION">
<span class="sig-name descname"><span class="pre">CLASSIFICATION</span></span><em class="property"> <span class="pre">=</span> <span class="pre">{'cifar_10':</span> <span class="pre">&lt;class</span> <span class="pre">'super_gradients.training.datasets.dataset_interfaces.dataset_interface.Cifar10DatasetInterface'&gt;,</span> <span class="pre">'cifar_100':</span> <span class="pre">&lt;class</span> <span class="pre">'super_gradients.training.datasets.dataset_interfaces.dataset_interface.Cifar100DatasetInterface'&gt;,</span> <span class="pre">'classification_dataset':</span> <span class="pre">&lt;class</span> <span class="pre">'super_gradients.training.datasets.dataset_interfaces.dataset_interface.ClassificationDatasetInterface'&gt;,</span> <span class="pre">'imagenet':</span> <span class="pre">&lt;class</span> <span class="pre">'super_gradients.training.datasets.dataset_interfaces.dataset_interface.ImageNetDatasetInterface'&gt;,</span> <span class="pre">'library_dataset':</span> <span class="pre">&lt;class</span> <span class="pre">'super_gradients.training.datasets.dataset_interfaces.dataset_interface.LibraryDatasetInterface'&gt;,</span> <span class="pre">'test_dataset':</span> <span class="pre">&lt;class</span> <span class="pre">'super_gradients.training.datasets.dataset_interfaces.dataset_interface.TestDatasetInterface'&gt;,</span> <span class="pre">'tiny_imagenet':</span> <span class="pre">&lt;class</span> <span class="pre">'super_gradients.training.datasets.dataset_interfaces.dataset_interface.TinyImageNetDatasetInterface'&gt;}</span></em><a class="headerlink" href="#super_gradients.training.datasets.all_datasets.SgLibraryDatasets.CLASSIFICATION" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.datasets.all_datasets.SgLibraryDatasets.OBJECT_DETECTION">
<span class="sig-name descname"><span class="pre">OBJECT_DETECTION</span></span><em class="property"> <span class="pre">=</span> <span class="pre">{'coco':</span> <span class="pre">&lt;class</span> <span class="pre">'super_gradients.training.datasets.dataset_interfaces.dataset_interface.CoCoDetectionDatasetInterface'&gt;,</span> <span class="pre">'coco2014':</span> <span class="pre">&lt;class</span> <span class="pre">'super_gradients.training.datasets.dataset_interfaces.dataset_interface.CoCo2014DetectionDatasetInterface'&gt;}</span></em><a class="headerlink" href="#super_gradients.training.datasets.all_datasets.SgLibraryDatasets.OBJECT_DETECTION" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.datasets.all_datasets.SgLibraryDatasets.SEMANTIC_SEGMENTATION">
<span class="sig-name descname"><span class="pre">SEMANTIC_SEGMENTATION</span></span><em class="property"> <span class="pre">=</span> <span class="pre">{'coco':</span> <span class="pre">&lt;class</span> <span class="pre">'super_gradients.training.datasets.dataset_interfaces.dataset_interface.CoCoSegmentationDatasetInterface'&gt;,</span> <span class="pre">'pascal_aug':</span> <span class="pre">&lt;class</span> <span class="pre">'super_gradients.training.datasets.dataset_interfaces.dataset_interface.PascalAUG2012SegmentationDataSetInterface'&gt;,</span> <span class="pre">'pascal_voc':</span> <span class="pre">&lt;class</span> <span class="pre">'super_gradients.training.datasets.dataset_interfaces.dataset_interface.PascalVOC2012SegmentationDataSetInterface'&gt;}</span></em><a class="headerlink" href="#super_gradients.training.datasets.all_datasets.SgLibraryDatasets.SEMANTIC_SEGMENTATION" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.datasets.all_datasets.SgLibraryDatasets.get_all_available_datasets">
<em class="property"><span class="pre">static</span> </em><span class="sig-name descname"><span class="pre">get_all_available_datasets</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; <span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><a class="reference internal" href="_modules/super_gradients/training/datasets/all_datasets.html#SgLibraryDatasets.get_all_available_datasets"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.datasets.all_datasets.SgLibraryDatasets.get_all_available_datasets" title="Permalink to this definition"></a></dt>
<dd><p>Gets all the available datasets.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.datasets.all_datasets.SgLibraryDatasets.get_dataset">
<em class="property"><span class="pre">static</span> </em><span class="sig-name descname"><span class="pre">get_dataset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dl_task</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataset_name</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">Type</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="super_gradients.training.datasets.dataset_interfaces.html#super_gradients.training.datasets.dataset_interfaces.dataset_interface.DatasetInterface" title="super_gradients.training.datasets.dataset_interfaces.dataset_interface.DatasetInterface"><span class="pre">super_gradients.training.datasets.dataset_interfaces.dataset_interface.DatasetInterface</span></a><span class="p"><span class="pre">]</span></span><a class="reference internal" href="_modules/super_gradients/training/datasets/all_datasets.html#SgLibraryDatasets.get_dataset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.datasets.all_datasets.SgLibraryDatasets.get_dataset" title="Permalink to this definition"></a></dt>
<dd><p>Get’s a dataset with a given name for a given deep learning task.
examp:
&gt;&gt;&gt; SgLibraryDatasets.get_dataset(dl_task=’classification’, dataset_name=’cifar_100’)
&gt;&gt;&gt; &lt;Cifar100DatasetInterface instance&gt;</p>
</dd></dl>

</dd></dl>

</section>
<section id="module-super_gradients.training.datasets.auto_augment">
<span id="super-gradients-training-datasets-auto-augment-module"></span><h2>super_gradients.training.datasets.auto_augment module<a class="headerlink" href="#module-super_gradients.training.datasets.auto_augment" title="Permalink to this headline"></a></h2>
<p>RandAugment
RandAugment is a variant of AutoAugment which randomly selects transformations</p>
<blockquote>
<div><p>from AutoAugment to be applied on an image.</p>
</div></blockquote>
<dl class="simple">
<dt>RandomAugmentation Implementation adapted from:</dt><dd><p><a class="reference external" href="https://github.com/rwightman/pytorch-image-models/blob/master/timm/data/auto_augment.py">https://github.com/rwightman/pytorch-image-models/blob/master/timm/data/auto_augment.py</a></p>
</dd>
<dt>Papers:</dt><dd><p>RandAugment: Practical automated data augmentation… - <a class="reference external" href="https://arxiv.org/abs/1909.13719">https://arxiv.org/abs/1909.13719</a></p>
</dd>
</dl>
<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.datasets.auto_augment.AugmentOp">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.datasets.auto_augment.</span></span><span class="sig-name descname"><span class="pre">AugmentOp</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prob</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">magnitude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hparams</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/datasets/auto_augment.html#AugmentOp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.datasets.auto_augment.AugmentOp" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>single auto augment operations</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.datasets.auto_augment.RandAugment">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.datasets.auto_augment.</span></span><span class="sig-name descname"><span class="pre">RandAugment</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ops</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_layers</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">choice_weights</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/datasets/auto_augment.html#RandAugment"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.datasets.auto_augment.RandAugment" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Random auto augment class, will select auto augment transforms according to probability weights for each op</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.datasets.auto_augment.auto_contrast">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.datasets.auto_augment.</span></span><span class="sig-name descname"><span class="pre">auto_contrast</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">__</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/datasets/auto_augment.html#auto_contrast"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.datasets.auto_augment.auto_contrast" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.datasets.auto_augment.brightness">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.datasets.auto_augment.</span></span><span class="sig-name descname"><span class="pre">brightness</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">factor</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">__</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/datasets/auto_augment.html#brightness"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.datasets.auto_augment.brightness" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.datasets.auto_augment.color">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.datasets.auto_augment.</span></span><span class="sig-name descname"><span class="pre">color</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">factor</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">__</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/datasets/auto_augment.html#color"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.datasets.auto_augment.color" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.datasets.auto_augment.contrast">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.datasets.auto_augment.</span></span><span class="sig-name descname"><span class="pre">contrast</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">factor</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">__</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/datasets/auto_augment.html#contrast"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.datasets.auto_augment.contrast" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.datasets.auto_augment.equalize">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.datasets.auto_augment.</span></span><span class="sig-name descname"><span class="pre">equalize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">__</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/datasets/auto_augment.html#equalize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.datasets.auto_augment.equalize" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.datasets.auto_augment.invert">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.datasets.auto_augment.</span></span><span class="sig-name descname"><span class="pre">invert</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">__</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/datasets/auto_augment.html#invert"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.datasets.auto_augment.invert" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.datasets.auto_augment.posterize">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.datasets.auto_augment.</span></span><span class="sig-name descname"><span class="pre">posterize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bits_to_keep</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">__</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/datasets/auto_augment.html#posterize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.datasets.auto_augment.posterize" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.datasets.auto_augment.rand_augment_ops">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.datasets.auto_augment.</span></span><span class="sig-name descname"><span class="pre">rand_augment_ops</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">magnitude</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hparams</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transforms</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/datasets/auto_augment.html#rand_augment_ops"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.datasets.auto_augment.rand_augment_ops" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.datasets.auto_augment.rand_augment_transform">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.datasets.auto_augment.</span></span><span class="sig-name descname"><span class="pre">rand_augment_transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">config_str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hparams</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/datasets/auto_augment.html#rand_augment_transform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.datasets.auto_augment.rand_augment_transform" title="Permalink to this definition"></a></dt>
<dd><p>Create a RandAugment transform</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>config_str</strong> – String defining configuration of random augmentation. Consists of multiple sections separated by</p>
</dd>
</dl>
<p>dashes (‘-‘). The first section defines the specific variant of rand augment (currently only ‘rand’). The remaining
sections, not order sepecific determine</p>
<blockquote>
<div><p>‘m’ - integer magnitude of rand augment
‘n’ - integer num layers (number of transform ops selected per image)
‘w’ - integer probabiliy weight index (index of a set of weights to influence choice of op)
‘mstd’ -  float std deviation of magnitude noise applied
‘inc’ - integer (bool), use augmentations that increase in severity with magnitude (default: 0)</p>
</div></blockquote>
<p>Ex ‘rand-m9-n3-mstd0.5’ results in RandAugment with magnitude 9, num_layers 3, magnitude_std 0.5
‘rand-mstd1-w0’ results in magnitude_std 1.0, weights 0, default magnitude of 10 and num_layers 2</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>hparams</strong> – Other hparams (kwargs) for the RandAugmentation scheme</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A PyTorch compatible Transform</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.datasets.auto_augment.rotate">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.datasets.auto_augment.</span></span><span class="sig-name descname"><span class="pre">rotate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">degrees</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/datasets/auto_augment.html#rotate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.datasets.auto_augment.rotate" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.datasets.auto_augment.sharpness">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.datasets.auto_augment.</span></span><span class="sig-name descname"><span class="pre">sharpness</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">factor</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">__</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/datasets/auto_augment.html#sharpness"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.datasets.auto_augment.sharpness" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.datasets.auto_augment.shear_x">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.datasets.auto_augment.</span></span><span class="sig-name descname"><span class="pre">shear_x</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">factor</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/datasets/auto_augment.html#shear_x"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.datasets.auto_augment.shear_x" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.datasets.auto_augment.shear_y">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.datasets.auto_augment.</span></span><span class="sig-name descname"><span class="pre">shear_y</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">factor</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/datasets/auto_augment.html#shear_y"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.datasets.auto_augment.shear_y" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.datasets.auto_augment.solarize">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.datasets.auto_augment.</span></span><span class="sig-name descname"><span class="pre">solarize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">thresh</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">__</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/datasets/auto_augment.html#solarize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.datasets.auto_augment.solarize" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.datasets.auto_augment.solarize_add">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.datasets.auto_augment.</span></span><span class="sig-name descname"><span class="pre">solarize_add</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">add</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">thresh</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">128</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">__</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/datasets/auto_augment.html#solarize_add"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.datasets.auto_augment.solarize_add" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.datasets.auto_augment.translate_x_abs">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.datasets.auto_augment.</span></span><span class="sig-name descname"><span class="pre">translate_x_abs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pixels</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/datasets/auto_augment.html#translate_x_abs"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.datasets.auto_augment.translate_x_abs" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.datasets.auto_augment.translate_x_rel">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.datasets.auto_augment.</span></span><span class="sig-name descname"><span class="pre">translate_x_rel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pct</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/datasets/auto_augment.html#translate_x_rel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.datasets.auto_augment.translate_x_rel" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.datasets.auto_augment.translate_y_abs">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.datasets.auto_augment.</span></span><span class="sig-name descname"><span class="pre">translate_y_abs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pixels</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/datasets/auto_augment.html#translate_y_abs"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.datasets.auto_augment.translate_y_abs" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.datasets.auto_augment.translate_y_rel">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.datasets.auto_augment.</span></span><span class="sig-name descname"><span class="pre">translate_y_rel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pct</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/datasets/auto_augment.html#translate_y_rel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.datasets.auto_augment.translate_y_rel" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</section>
<section id="module-super_gradients.training.datasets.data_augmentation">
<span id="super-gradients-training-datasets-data-augmentation-module"></span><h2>super_gradients.training.datasets.data_augmentation module<a class="headerlink" href="#module-super_gradients.training.datasets.data_augmentation" title="Permalink to this headline"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.datasets.data_augmentation.DataAugmentation">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.datasets.data_augmentation.</span></span><span class="sig-name descname"><span class="pre">DataAugmentation</span></span><a class="reference internal" href="_modules/super_gradients/training/datasets/data_augmentation.html#DataAugmentation"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.datasets.data_augmentation.DataAugmentation" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.datasets.data_augmentation.DataAugmentation.cutout">
<em class="property"><span class="pre">static</span> </em><span class="sig-name descname"><span class="pre">cutout</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mask_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cutout_inside</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask_color</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0,</span> <span class="pre">0,</span> <span class="pre">0)</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/datasets/data_augmentation.html#DataAugmentation.cutout"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.datasets.data_augmentation.DataAugmentation.cutout" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.datasets.data_augmentation.DataAugmentation.normalize">
<em class="property"><span class="pre">static</span> </em><span class="sig-name descname"><span class="pre">normalize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mean</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">std</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/datasets/data_augmentation.html#DataAugmentation.normalize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.datasets.data_augmentation.DataAugmentation.normalize" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.datasets.data_augmentation.DataAugmentation.to_tensor">
<em class="property"><span class="pre">static</span> </em><span class="sig-name descname"><span class="pre">to_tensor</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/datasets/data_augmentation.html#DataAugmentation.to_tensor"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.datasets.data_augmentation.DataAugmentation.to_tensor" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.datasets.data_augmentation.Lighting">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.datasets.data_augmentation.</span></span><span class="sig-name descname"><span class="pre">Lighting</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">alphastd</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eigval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">tensor([0.2175,</span> <span class="pre">0.0188,</span> <span class="pre">0.0045])</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eigvec</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">tensor([[-</span> <span class="pre">0.5675,</span> <span class="pre">0.7192,</span> <span class="pre">0.4009],</span> <span class="pre">[-</span> <span class="pre">0.5808,</span> <span class="pre">-</span> <span class="pre">0.0045,</span> <span class="pre">-</span> <span class="pre">0.814],</span> <span class="pre">[-</span> <span class="pre">0.5836,</span> <span class="pre">-</span> <span class="pre">0.6948,</span> <span class="pre">0.4203]])</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/datasets/data_augmentation.html#Lighting"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.datasets.data_augmentation.Lighting" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Lighting noise(AlexNet - style PCA - based noise)
Taken from fastai Imagenet training - <a class="reference external" href="https://github.com/fastai/imagenet-fast/blob/faa0f9dfc9e8e058ffd07a248724bf384f526fae/imagenet_nv/fastai_imagenet.py#L103">https://github.com/fastai/imagenet-fast/blob/faa0f9dfc9e8e058ffd07a248724bf384f526fae/imagenet_nv/fastai_imagenet.py#L103</a>
To use:</p>
<blockquote>
<div><ul class="simple">
<li><p>training_params = {“imagenet_pca_aug”: 0.1}</p></li>
<li><p>Default training_params arg is 0.0 (“don’t use”)</p></li>
<li><p>0.1 is that default in the original paper</p></li>
</ul>
</div></blockquote>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.datasets.data_augmentation.RandomErase">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.datasets.data_augmentation.</span></span><span class="sig-name descname"><span class="pre">RandomErase</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">probability</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">value</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/datasets/data_augmentation.html#RandomErase"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.datasets.data_augmentation.RandomErase" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torchvision.transforms.transforms.RandomErasing</span></code></p>
<p>A simple class that translates the parameters supported in SuperGradient’s code base</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.datasets.data_augmentation.RandomErase.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.datasets.data_augmentation.RandomErase.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="module-super_gradients.training.datasets.datasets_conf">
<span id="super-gradients-training-datasets-datasets-conf-module"></span><h2>super_gradients.training.datasets.datasets_conf module<a class="headerlink" href="#module-super_gradients.training.datasets.datasets_conf" title="Permalink to this headline"></a></h2>
</section>
<section id="module-super_gradients.training.datasets.datasets_utils">
<span id="super-gradients-training-datasets-datasets-utils-module"></span><h2>super_gradients.training.datasets.datasets_utils module<a class="headerlink" href="#module-super_gradients.training.datasets.datasets_utils" title="Permalink to this headline"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.datasets.datasets_utils.AbstractCollateFunction">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.datasets.datasets_utils.</span></span><span class="sig-name descname"><span class="pre">AbstractCollateFunction</span></span><a class="reference internal" href="_modules/super_gradients/training/datasets/datasets_utils.html#AbstractCollateFunction"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.datasets.datasets_utils.AbstractCollateFunction" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">abc.ABC</span></code></p>
<p>A collate function (for torch DataLoader)</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.datasets.datasets_utils.AtomicInteger">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.datasets.datasets_utils.</span></span><span class="sig-name descname"><span class="pre">AtomicInteger</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">value</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/datasets/datasets_utils.html#AtomicInteger"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.datasets.datasets_utils.AtomicInteger" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.datasets.datasets_utils.ComposedCollateFunction">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.datasets.datasets_utils.</span></span><span class="sig-name descname"><span class="pre">ComposedCollateFunction</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">functions</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">list</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/datasets/datasets_utils.html#ComposedCollateFunction"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.datasets.datasets_utils.ComposedCollateFunction" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.datasets.datasets_utils.AbstractCollateFunction" title="super_gradients.training.datasets.datasets_utils.AbstractCollateFunction"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.datasets.datasets_utils.AbstractCollateFunction</span></code></a></p>
<p>A function (for torch DataLoader) which executes a sequence of sub collate functions</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.datasets.datasets_utils.DatasetStatisticsTensorboardLogger">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.datasets.datasets_utils.</span></span><span class="sig-name descname"><span class="pre">DatasetStatisticsTensorboardLogger</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">writer</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">torch.utils.tensorboard.writer.SummaryWriter</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">summary_params</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">dict</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">{'max_batches':</span> <span class="pre">30,</span> <span class="pre">'plot_anchors_coverage':</span> <span class="pre">True,</span> <span class="pre">'plot_box_size_distribution':</span> <span class="pre">True,</span> <span class="pre">'plot_class_distribution':</span> <span class="pre">True,</span> <span class="pre">'sample_images':</span> <span class="pre">32}</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/datasets/datasets_utils.html#DatasetStatisticsTensorboardLogger"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.datasets.datasets_utils.DatasetStatisticsTensorboardLogger" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.datasets.datasets_utils.DatasetStatisticsTensorboardLogger.DEFAULT_SUMMARY_PARAMS">
<span class="sig-name descname"><span class="pre">DEFAULT_SUMMARY_PARAMS</span></span><em class="property"> <span class="pre">=</span> <span class="pre">{'max_batches':</span> <span class="pre">30,</span> <span class="pre">'plot_anchors_coverage':</span> <span class="pre">True,</span> <span class="pre">'plot_box_size_distribution':</span> <span class="pre">True,</span> <span class="pre">'plot_class_distribution':</span> <span class="pre">True,</span> <span class="pre">'sample_images':</span> <span class="pre">32}</span></em><a class="headerlink" href="#super_gradients.training.datasets.datasets_utils.DatasetStatisticsTensorboardLogger.DEFAULT_SUMMARY_PARAMS" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.datasets.datasets_utils.DatasetStatisticsTensorboardLogger.analyze">
<span class="sig-name descname"><span class="pre">analyze</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data_loader</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">torch.utils.data.dataloader.DataLoader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataset_params</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">title</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">anchors</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">list</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/datasets/datasets_utils.html#DatasetStatisticsTensorboardLogger.analyze"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.datasets.datasets_utils.DatasetStatisticsTensorboardLogger.analyze" title="Permalink to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data_loader</strong> – the dataset data loader</p></li>
<li><p><strong>dataset_params</strong> – the dataset parameters</p></li>
<li><p><strong>title</strong> – the title for this dataset (i.e. Coco 2017 test set)</p></li>
<li><p><strong>anchors</strong> – the list of anchors used by the model. applicable only for detection datasets</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.datasets.datasets_utils.DatasetStatisticsTensorboardLogger.logger">
<span class="sig-name descname"><span class="pre">logger</span></span><em class="property"> <span class="pre">=</span> <span class="pre">&lt;Logger</span> <span class="pre">super_gradients.training.datasets.datasets_utils</span> <span class="pre">(INFO)&gt;</span></em><a class="headerlink" href="#super_gradients.training.datasets.datasets_utils.DatasetStatisticsTensorboardLogger.logger" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.datasets.datasets_utils.MultiScaleCollateFunction">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.datasets.datasets_utils.</span></span><span class="sig-name descname"><span class="pre">MultiScaleCollateFunction</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target_size</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_image_size</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_image_size</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">image_size_steps</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">32</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">change_frequency</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">10</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/datasets/datasets_utils.html#MultiScaleCollateFunction"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.datasets.datasets_utils.MultiScaleCollateFunction" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.datasets.datasets_utils.AbstractCollateFunction" title="super_gradients.training.datasets.datasets_utils.AbstractCollateFunction"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.datasets.datasets_utils.AbstractCollateFunction</span></code></a></p>
<p>a collate function to implement multi-scale data augmentation
according to <a class="reference external" href="https://arxiv.org/pdf/1612.08242.pdf">https://arxiv.org/pdf/1612.08242.pdf</a></p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.datasets.datasets_utils.RandomResizedCropAndInterpolation">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.datasets.datasets_utils.</span></span><span class="sig-name descname"><span class="pre">RandomResizedCropAndInterpolation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0.08,</span> <span class="pre">1.0)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ratio</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0.75,</span> <span class="pre">1.3333333333333333)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">interpolation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'default'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/datasets/datasets_utils.html#RandomResizedCropAndInterpolation"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.datasets.datasets_utils.RandomResizedCropAndInterpolation" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torchvision.transforms.transforms.RandomResizedCrop</span></code></p>
<p>Crop the given PIL Image to random size and aspect ratio with explicitly chosen or random interpolation.</p>
<p>A crop of random size (default: of 0.08 to 1.0) of the original size and a random
aspect ratio (default: of 3/4 to 4/3) of the original aspect ratio is made. This crop
is finally resized to given size.
This is popularly used to train the Inception networks.</p>
<dl class="simple">
<dt>Args:</dt><dd><p>size: expected output size of each edge
scale: range of size of the origin size cropped
ratio: range of aspect ratio of the origin aspect ratio cropped
interpolation: Default: PIL.Image.BILINEAR</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.datasets.datasets_utils.RandomResizedCropAndInterpolation.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/datasets/datasets_utils.html#RandomResizedCropAndInterpolation.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.datasets.datasets_utils.RandomResizedCropAndInterpolation.forward" title="Permalink to this definition"></a></dt>
<dd><dl class="simple">
<dt>Args:</dt><dd><p>img (PIL Image): Image to be cropped and resized.</p>
</dd>
<dt>Returns:</dt><dd><p>PIL Image: Randomly cropped and resized image.</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.datasets.datasets_utils.RandomResizedCropAndInterpolation.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.datasets.datasets_utils.RandomResizedCropAndInterpolation.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.datasets.datasets_utils.get_color_augmentation">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.datasets.datasets_utils.</span></span><span class="sig-name descname"><span class="pre">get_color_augmentation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">rand_augment_config_string</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">color_jitter</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">tuple</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">crop_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">224</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">img_mean</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[0.485,</span> <span class="pre">0.456,</span> <span class="pre">0.406]</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/datasets/datasets_utils.html#get_color_augmentation"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.datasets.datasets_utils.get_color_augmentation" title="Permalink to this definition"></a></dt>
<dd><p>Returns color augmentation class. As these augmentation cannot work on top one another, only one is returned according to rand_augment_config_string
:param rand_augment_config_string: string which defines the auto augment configurations. If none, color jitter will be returned. For possibile values see auto_augment.py
:param color_jitter: tuple for color jitter value.
:param crop_size: relevant only for auto augment
:param img_mean: relevant only for auto augment
:return: RandAugment transform or ColorJitter</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.datasets.datasets_utils.get_mean_and_std">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.datasets.datasets_utils.</span></span><span class="sig-name descname"><span class="pre">get_mean_and_std</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataset</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/datasets/datasets_utils.html#get_mean_and_std"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.datasets.datasets_utils.get_mean_and_std" title="Permalink to this definition"></a></dt>
<dd><p>Compute the mean and std value of dataset.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.datasets.datasets_utils.get_mean_and_std_torch">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.datasets.datasets_utils.</span></span><span class="sig-name descname"><span class="pre">get_mean_and_std_torch</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data_dir</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_workers</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">RandomResizeSize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">224</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/datasets/datasets_utils.html#get_mean_and_std_torch"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.datasets.datasets_utils.get_mean_and_std_torch" title="Permalink to this definition"></a></dt>
<dd><p>A function for getting the mean and std of large datasets using pytorch dataloader and gpu functionality.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data_dir</strong> – String, path to none-library dataset folder. For example “/data/Imagenette” or “/data/TinyImagenet”</p></li>
<li><p><strong>dataloader</strong> – a torch DataLoader, as it would feed the data into the trainer (including transforms etc).</p></li>
<li><p><strong>RandomResizeSize</strong> – Int, the size of the RandomResizeCrop as it appears in the DataInterface (for example, for Imagenet,</p></li>
</ul>
</dd>
</dl>
<p>this value should be 224).
:return: 2 lists,mean and std, each one of len 3 (1 for each channel)</p>
</dd></dl>

</section>
<section id="module-super_gradients.training.datasets.mixup">
<span id="super-gradients-training-datasets-mixup-module"></span><h2>super_gradients.training.datasets.mixup module<a class="headerlink" href="#module-super_gradients.training.datasets.mixup" title="Permalink to this headline"></a></h2>
<p>Mixup and Cutmix</p>
<p>Papers:
mixup: Beyond Empirical Risk Minimization (<a class="reference external" href="https://arxiv.org/abs/1710.09412">https://arxiv.org/abs/1710.09412</a>)</p>
<p>CutMix: Regularization Strategy to Train Strong Classifiers with Localizable Features (<a class="reference external" href="https://arxiv.org/abs/1905.04899">https://arxiv.org/abs/1905.04899</a>)</p>
<p>Code Reference:
CutMix: <a class="reference external" href="https://github.com/clovaai/CutMix-PyTorch">https://github.com/clovaai/CutMix-PyTorch</a>
CutMix by timm: <a class="reference external" href="https://github.com/rwightman/pytorch-image-models/timm">https://github.com/rwightman/pytorch-image-models/timm</a></p>
<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.datasets.mixup.CollateMixup">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.datasets.mixup.</span></span><span class="sig-name descname"><span class="pre">CollateMixup</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mixup_alpha</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">float</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cutmix_alpha</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">float</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cutmix_minmax</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prob</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">float</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">switch_prob</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">float</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">'batch'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">correct_lam</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">label_smoothing</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">float</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_classes</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">1000</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/datasets/mixup.html#CollateMixup"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.datasets.mixup.CollateMixup" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Collate with Mixup/Cutmix that applies different params to each element or whole batch
A Mixup impl that’s performed while collating the batches.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.datasets.mixup.cutmix_bbox_and_lam">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.datasets.mixup.</span></span><span class="sig-name descname"><span class="pre">cutmix_bbox_and_lam</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img_shape</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">tuple</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lam</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ratio_minmax</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">tuple</span><span class="p"><span class="pre">,</span> </span><span class="pre">list</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">correct_lam</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">count</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/datasets/mixup.html#cutmix_bbox_and_lam"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.datasets.mixup.cutmix_bbox_and_lam" title="Permalink to this definition"></a></dt>
<dd><p>Generate bbox and apply lambda correction.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.datasets.mixup.mixup_target">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.datasets.mixup.</span></span><span class="sig-name descname"><span class="pre">mixup_target</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_classes</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lam</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">float</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">smoothing</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">float</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">'cuda'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/datasets/mixup.html#mixup_target"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.datasets.mixup.mixup_target" title="Permalink to this definition"></a></dt>
<dd><p>generate a smooth target (label) two-hot tensor to support the mixed images with different labels
:param target: the targets tensor
:param num_classes: number of classes (to set the final tensor size)
:param lam: percentage of label a range [0, 1] in the mixing
:param smoothing: the smoothing multiplier
:param device: usable device [‘cuda’, ‘cpu’]
:return:</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.datasets.mixup.one_hot">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.datasets.mixup.</span></span><span class="sig-name descname"><span class="pre">one_hot</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_classes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">on_value</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">off_value</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'cuda'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/datasets/mixup.html#one_hot"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.datasets.mixup.one_hot" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.datasets.mixup.rand_bbox">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.datasets.mixup.</span></span><span class="sig-name descname"><span class="pre">rand_bbox</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img_shape</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">tuple</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lam</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">margin</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">float</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">count</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/datasets/mixup.html#rand_bbox"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.datasets.mixup.rand_bbox" title="Permalink to this definition"></a></dt>
<dd><p>Standard CutMix bounding-box
Generates a random square bbox based on lambda value. This impl includes
support for enforcing a border margin as percent of bbox dimensions.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>img_shape</strong> – Image shape as tuple</p></li>
<li><p><strong>lam</strong> – Cutmix lambda value</p></li>
<li><p><strong>margin</strong> – Percentage of bbox dimension to enforce as margin (reduce amount of box outside image)</p></li>
<li><p><strong>count</strong> – Number of bbox to generate</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.datasets.mixup.rand_bbox_minmax">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.datasets.mixup.</span></span><span class="sig-name descname"><span class="pre">rand_bbox_minmax</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img_shape</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">tuple</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">minmax</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">tuple</span><span class="p"><span class="pre">,</span> </span><span class="pre">list</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">count</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/datasets/mixup.html#rand_bbox_minmax"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.datasets.mixup.rand_bbox_minmax" title="Permalink to this definition"></a></dt>
<dd><p>Min-Max CutMix bounding-box
Inspired by Darknet cutmix impl, generates a random rectangular bbox
based on min/max percent values applied to each dimension of the input image.</p>
<p>Typical defaults for minmax are usually in the  .2-.3 for min and .8-.9 range for max.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>img_shape</strong> – Image shape as tuple</p></li>
<li><p><strong>minmax</strong> – Min and max bbox ratios (as percent of image size)</p></li>
<li><p><strong>count</strong> – Number of bbox to generate</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-super_gradients.training.datasets.sg_dataset">
<span id="super-gradients-training-datasets-sg-dataset-module"></span><h2>super_gradients.training.datasets.sg_dataset module<a class="headerlink" href="#module-super_gradients.training.datasets.sg_dataset" title="Permalink to this headline"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.datasets.sg_dataset.BaseSgVisionDataset">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.datasets.sg_dataset.</span></span><span class="sig-name descname"><span class="pre">BaseSgVisionDataset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">root:</span> <span class="pre">str</span></em>, <em class="sig-param"><span class="pre">sample_loader:</span> <span class="pre">Callable</span> <span class="pre">=</span> <span class="pre">&lt;function</span> <span class="pre">default_loader&gt;</span></em>, <em class="sig-param"><span class="pre">target_loader:</span> <span class="pre">Optional[Callable]</span> <span class="pre">=</span> <span class="pre">None</span></em>, <em class="sig-param"><span class="pre">collate_fn:</span> <span class="pre">Optional[Callable]</span> <span class="pre">=</span> <span class="pre">None</span></em>, <em class="sig-param"><span class="pre">valid_sample_extensions:</span> <span class="pre">tuple</span> <span class="pre">=</span> <span class="pre">('.jpg'</span></em>, <em class="sig-param"><span class="pre">'.jpeg'</span></em>, <em class="sig-param"><span class="pre">'.png'</span></em>, <em class="sig-param"><span class="pre">'.ppm'</span></em>, <em class="sig-param"><span class="pre">'.bmp'</span></em>, <em class="sig-param"><span class="pre">'.pgm'</span></em>, <em class="sig-param"><span class="pre">'.tif'</span></em>, <em class="sig-param"><span class="pre">'.tiff'</span></em>, <em class="sig-param"><span class="pre">'.webp')</span></em>, <em class="sig-param"><span class="pre">sample_transform:</span> <span class="pre">Optional[Callable]</span> <span class="pre">=</span> <span class="pre">None</span></em>, <em class="sig-param"><span class="pre">target_transform:</span> <span class="pre">Optional[Callable]</span> <span class="pre">=</span> <span class="pre">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/datasets/sg_dataset.html#BaseSgVisionDataset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.datasets.sg_dataset.BaseSgVisionDataset" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Generic</span></code>[<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.utils.data.dataset.T_co</span></code>]</p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.datasets.sg_dataset.BaseSgVisionDataset.numpy_loader_func">
<em class="property"><span class="pre">static</span> </em><span class="sig-name descname"><span class="pre">numpy_loader_func</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/datasets/sg_dataset.html#BaseSgVisionDataset.numpy_loader_func"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.datasets.sg_dataset.BaseSgVisionDataset.numpy_loader_func" title="Permalink to this definition"></a></dt>
<dd><dl class="simple">
<dt>_numpy_loader_func - Uses numpy load func</dt><dd><dl class="field-list simple">
<dt class="field-odd">param path</dt>
<dd class="field-odd"><p></p></dd>
<dt class="field-even">return</dt>
<dd class="field-even"><p></p></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.datasets.sg_dataset.BaseSgVisionDataset.text_file_loader_func">
<em class="property"><span class="pre">static</span> </em><span class="sig-name descname"><span class="pre">text_file_loader_func</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text_file_path</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inline_splitter</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">'</span> <span class="pre">'</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">list</span><a class="reference internal" href="_modules/super_gradients/training/datasets/sg_dataset.html#BaseSgVisionDataset.text_file_loader_func"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.datasets.sg_dataset.BaseSgVisionDataset.text_file_loader_func" title="Permalink to this definition"></a></dt>
<dd><blockquote>
<div><dl class="simple">
<dt>text_file_loader_func - Uses a line by line based code to get vectorized data from a text-based file</dt><dd><dl class="field-list simple">
<dt class="field-odd">param text_file_path</dt>
<dd class="field-odd"><p>Input text file</p>
</dd>
<dt class="field-even">param inline_splitter</dt>
<dd class="field-even"><p>The char to use in order to separate between different VALUES of the SAME vector
please notice that DIFFERENT VECTORS SHOULD BE IN SEPARATE LINES (’</p>
</dd>
</dl>
</dd>
</dl>
</div></blockquote>
<dl class="simple">
<dt>‘) SEPARATED</dt><dd><dl class="field-list simple">
<dt class="field-odd">return</dt>
<dd class="field-odd"><p>a list of tuples, where each tuple is a vector of target values</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.datasets.sg_dataset.DirectoryDataSet">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.datasets.sg_dataset.</span></span><span class="sig-name descname"><span class="pre">DirectoryDataSet</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">root:</span> <span class="pre">str</span></em>, <em class="sig-param"><span class="pre">samples_sub_directory:</span> <span class="pre">str</span></em>, <em class="sig-param"><span class="pre">targets_sub_directory:</span> <span class="pre">str</span></em>, <em class="sig-param"><span class="pre">target_extension:</span> <span class="pre">str</span></em>, <em class="sig-param"><span class="pre">sample_loader:</span> <span class="pre">Callable</span> <span class="pre">=</span> <span class="pre">&lt;function</span> <span class="pre">default_loader&gt;</span></em>, <em class="sig-param"><span class="pre">target_loader:</span> <span class="pre">Optional[Callable]</span> <span class="pre">=</span> <span class="pre">None</span></em>, <em class="sig-param"><span class="pre">collate_fn:</span> <span class="pre">Optional[Callable]</span> <span class="pre">=</span> <span class="pre">None</span></em>, <em class="sig-param"><span class="pre">sample_extensions:</span> <span class="pre">tuple</span> <span class="pre">=</span> <span class="pre">('.jpg'</span></em>, <em class="sig-param"><span class="pre">'.jpeg'</span></em>, <em class="sig-param"><span class="pre">'.png'</span></em>, <em class="sig-param"><span class="pre">'.ppm'</span></em>, <em class="sig-param"><span class="pre">'.bmp'</span></em>, <em class="sig-param"><span class="pre">'.pgm'</span></em>, <em class="sig-param"><span class="pre">'.tif'</span></em>, <em class="sig-param"><span class="pre">'.tiff'</span></em>, <em class="sig-param"><span class="pre">'.webp')</span></em>, <em class="sig-param"><span class="pre">sample_transform:</span> <span class="pre">Optional[Callable]</span> <span class="pre">=</span> <span class="pre">None</span></em>, <em class="sig-param"><span class="pre">target_transform:</span> <span class="pre">Optional[Callable]</span> <span class="pre">=</span> <span class="pre">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/datasets/sg_dataset.html#DirectoryDataSet"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.datasets.sg_dataset.DirectoryDataSet" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Generic</span></code>[<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.utils.data.dataset.T_co</span></code>]</p>
<dl class="simple">
<dt>DirectoryDataSet - A PyTorch Vision Data Set extension that receives a root Dir and two separate sub directories:</dt><dd><ul class="simple">
<li><p>Sub-Directory for Samples</p></li>
<li><p>Sub-Directory for Targets</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.datasets.sg_dataset.ListDataset">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.datasets.sg_dataset.</span></span><span class="sig-name descname"><span class="pre">ListDataset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">root</span></em>, <em class="sig-param"><span class="pre">file</span></em>, <em class="sig-param"><span class="pre">sample_loader:</span> <span class="pre">Callable</span> <span class="pre">=</span> <span class="pre">&lt;function</span> <span class="pre">default_loader&gt;</span></em>, <em class="sig-param"><span class="pre">target_loader:</span> <span class="pre">Optional[Callable]</span> <span class="pre">=</span> <span class="pre">None</span></em>, <em class="sig-param"><span class="pre">collate_fn:</span> <span class="pre">Optional[Callable]</span> <span class="pre">=</span> <span class="pre">None</span></em>, <em class="sig-param"><span class="pre">sample_extensions:</span> <span class="pre">tuple</span> <span class="pre">=</span> <span class="pre">('.jpg'</span></em>, <em class="sig-param"><span class="pre">'.jpeg'</span></em>, <em class="sig-param"><span class="pre">'.png'</span></em>, <em class="sig-param"><span class="pre">'.ppm'</span></em>, <em class="sig-param"><span class="pre">'.bmp'</span></em>, <em class="sig-param"><span class="pre">'.pgm'</span></em>, <em class="sig-param"><span class="pre">'.tif'</span></em>, <em class="sig-param"><span class="pre">'.tiff'</span></em>, <em class="sig-param"><span class="pre">'.webp')</span></em>, <em class="sig-param"><span class="pre">sample_transform:</span> <span class="pre">Optional[Callable]</span> <span class="pre">=</span> <span class="pre">None</span></em>, <em class="sig-param"><span class="pre">target_transform:</span> <span class="pre">Optional[Callable]</span> <span class="pre">=</span> <span class="pre">None</span></em>, <em class="sig-param"><span class="pre">target_extension='.npy'</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/datasets/sg_dataset.html#ListDataset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.datasets.sg_dataset.ListDataset" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Generic</span></code>[<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.utils.data.dataset.T_co</span></code>]</p>
<dl>
<dt>ListDataset - A PyTorch Vision Data Set extension that receives a file with FULL PATH to each of the samples.</dt><dd><p>Then, the assumption is that for every sample, there is a * matching target * in the same
path but with a different extension, i.e:</p>
<blockquote>
<div><dl class="simple">
<dt>for the samples paths:  (That appear in the list file)</dt><dd><p>/root/dataset/class_x/sample1.png
/root/dataset/class_y/sample123.png</p>
</dd>
<dt>the matching labels paths:  (That DO NOT appear in the list file)</dt><dd><p>/root/dataset/class_x/sample1.ext
/root/dataset/class_y/sample123.ext</p>
</dd>
</dl>
</div></blockquote>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-super_gradients.training.datasets">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-super_gradients.training.datasets" title="Permalink to this headline"></a></h2>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="super_gradients.training.html" class="btn btn-neutral float-left" title="super_gradients.training package" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="super_gradients.training.datasets.classification_datasets.html" class="btn btn-neutral float-right" title="super_gradients.training.datasets.classification_datasets package" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, SuperGradients team.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>